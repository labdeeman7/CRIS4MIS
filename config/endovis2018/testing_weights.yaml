DATA:
  dataset: endovis2018
  train_data_file: cris_train_2018.json
  train_data_root: ../data/endovis_2018_all_seq_full_size/train
  val_data_file: cris_val_2018.json
  val_data_root: ../data/endovis_2018_all_seq_full_size/val
  sents_select_type: "random"
  use_vis_aug: False
  use_vis_aug_non_rigid: False
TRAIN:
  freeze_modules: []
  # Base Arch
  clip_pretrain: pretrain/RN50.pt
  input_size: 416
  word_len: 17
  word_dim: 1024
  vis_dim: 512
  fpn_in: [512, 1024, 1024]
  fpn_out: [256, 512, 1024]
  sync_bn: True
  # Decoder
  num_layers: 3
  num_head: 8
  dim_ffn: 2048
  dropout: 0.1
  intermediate: False
  # MaskIoU
  pred_mask_iou: False
  mask_iou_loss_type: "mse"
  mask_iou_loss_weight: 1.0
  # MoE
  use_moe_select_best_sent: False
  max_sent_num: 7
  use_moe_consistency_loss: False
  moe_consistency_loss_weight: 1.0
  # MAE
  use_mae_gen_target_area: False
  mae_pretrain: 'pretrain/mae_pretrain_vit_base.pth'
  reconstruct_full_img: False
  mae_hard_example_mining_type: null
  # Training Setting
  workers: 8  # data loader workers
  workers_val: 4
  epochs: 1
  milestones: [35]
  start_epoch: 0
  batch_size: 64  # batch size for training
  batch_size_val: 64  # batch size for validation during training, memory and speed tradeoff
  base_lr: 0.0001
  lr_decay: 0.1
  lr_multi: 0.1
  weight_decay: 0.
  max_norm: 0.
  manual_seed: 0
  print_freq: 100
  # Resume & Save
  exp_name: CRIS_R50
  output_folder: exp/endovis2018
  save_freq: 1
  weight:  # path to initial weight (default: none)
  resume:  # path to latest checkpoint (default: none)
  evaluate: True  # evaluate on validation set, extra gpu memory needed and small batch_size_val is recommend
  # debug
  testing_trainable_weights: True
Distributed:
  dist_url: tcp://localhost:3681
  dist_backend: 'nccl'
  multiprocessing_distributed: True
  world_size: 1
  rank: 0
TEST:
  test_data_file: cris_val_2018.json
  test_data_root: ../data/endovis_2018_all_seq_full_size/val
  visualize: False